import torch
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader
from tqdm import tqdm
import os
from sklearn.metrics import r2_score

# å¼•å…¥ä½ çš„æ¨¡å—
from dataset import SpeckleVoxelDataset
from model import SnnRegressor

# ================= é…ç½®åŒºåŸŸ (éœ€ä¸ train.py ä¸¥æ ¼ä¸€è‡´) =================
# åªä¿ç•™ 0.2 - 2.2 mm/s çš„æ¸…æ´—æ•°æ®
FULL_CONFIG = {
    'files': {
        0.2: [r'/data/zm/12.23data/0.2mm_clip.csv'],
        0.5: [r'/data/zm/12.23data/0.5mm_clip.csv'],
        0.8: [r'/data/zm/12.23data/0.8mm_clip.csv'],
        1.0: [r'/data/zm/12.23data/1.0mm_clip.csv'],
        1.2: [r'/data/zm/12.23data/1.2mm_clip.csv'],
        1.5: [r'/data/zm/12.23data/1.5mm_clip.csv'],
        1.8: [r'/data/zm/12.23data/1.8mm_clip.csv'],
        2.0: [r'/data/zm/12.23data/2.0mm_clip.csv'],
        2.2: [r'/data/zm/12.23data/2.2mm_clip.csv'],
    },
    'roi': {'row_start': 400, 'row_end': 499, 'col_start': 0, 'col_end': 1280},
    'window_size_ms': 25,
    'stride_ms': 25,  # è¯„ä¼°æ—¶æ­¥é•¿è®¾å¤§ä¸€ç‚¹ï¼Œé¿å…é‡å¤è®¡ç®—ï¼Œçœ‹æ•´ä½“è¶‹åŠ¿
    'crop_size': 64
}

BATCH_SIZE = 64
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# æŒ‡å‘ä½ åˆšæ‰è·‘å‡º 0.3201 çš„é‚£ä¸ªæœ€ä½³æ¨¡å‹
MODEL_PATH = "/data/zm/12.22/03_snn_dropout_0.3091.pth"


def plot_results(preds, labels):
    """
    ç»˜åˆ¶å›å½’åˆ†æå›¾å’Œè¯¯å·®åˆ†å¸ƒå›¾
    """
    plt.figure(figsize=(15, 6))

    # --- å­å›¾ 1: å›å½’åˆ†æ ---
    plt.subplot(1, 2, 1)

    # æ•£ç‚¹å›¾
    plt.scatter(labels, preds, alpha=0.4, s=15, color='#4169E1', label='Test Samples')

    # ç†æƒ³çº¿ (y=x)
    min_val = min(labels.min(), preds.min())
    max_val = max(labels.max(), preds.max())
    plt.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Perfect Fit')

    # è®¡ç®—æŒ‡æ ‡
    rmse = np.sqrt(np.mean((preds - labels) ** 2))
    r2 = r2_score(labels, preds)

    plt.title(f'Regression Analysis\nRMSE={rmse:.4f}, RÂ²={r2:.4f}')
    plt.xlabel('Ground Truth Velocity (mm/s)')
    plt.ylabel('Predicted Velocity (mm/s)')
    plt.legend()
    plt.grid(True, linestyle='--', alpha=0.5)

    # --- å­å›¾ 2: è¯¯å·®ç®±çº¿å›¾ ---
    plt.subplot(1, 2, 2)

    # æŒ‰çœŸå®æµé€Ÿåˆ†ç»„è®¡ç®—è¯¯å·®
    unique_labels = np.unique(labels)
    errors_by_label = []
    labels_str = []

    for label in unique_labels:
        mask = (labels == label)
        # è¯¯å·® = é¢„æµ‹ - çœŸå®
        errors = preds[mask] - labels[mask]
        errors_by_label.append(errors)
        labels_str.append(f"{label:.2f}")

    plt.boxplot(errors_by_label, labels=labels_str, patch_artist=False, showfliers=False)
    plt.axhline(0, color='r', linestyle='--', linewidth=1)

    plt.title('Error Distribution by Velocity')
    plt.xlabel('Velocity Group (mm/s)')
    plt.ylabel('Prediction Error (mm/s)')
    plt.grid(True, linestyle='--', alpha=0.5)

    plt.tight_layout()
    plt.savefig('evaluation_result_mlp.png', dpi=300)
    print("âœ… è¯„ä¼°å›¾è¡¨å·²ä¿å­˜ä¸º evaluation_result_mlp.png")
    plt.show()


def main():
    print(f"Using device: {DEVICE}")

    # 1. åŠ è½½æµ‹è¯•é›†
    # is_train=False ä¼šè‡ªåŠ¨é€‰æ‹©æ¯ä¸ªæ–‡ä»¶å 20% çš„æ—¶é—´æ®µ
    # å¹¶ä¸” dataset å†…éƒ¨ä¼šè‡ªåŠ¨å…³é—­ Dropout
    test_dataset = SpeckleVoxelDataset(FULL_CONFIG, is_train=False)
    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)
    print(f"Test samples (Last 20% of time): {len(test_dataset)}")

    # 2. åŠ è½½æ¨¡å‹
    if not os.path.exists(MODEL_PATH):
        print(f"âŒ Error: Model file not found at {MODEL_PATH}")
        return

    model = SnnRegressor(crop_size=FULL_CONFIG['crop_size']).to(DEVICE)

    # åŠ è½½æƒé‡
    try:
        checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)
        model.load_state_dict(checkpoint)
        print("âœ… æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸï¼")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return

    model.eval()

    # 3. æ¨ç†
    all_preds = []
    all_labels = []

    print("Running evaluation...")
    with torch.no_grad():
        # dataset ç°åœ¨è¿”å› 3 ä¸ªå€¼: (voxel, label, density)
        # æˆ‘ä»¬è¿™é‡Œåªéœ€è¦å‰ä¸¤ä¸ª
        for inputs, labels, _ in tqdm(test_loader):
            inputs = inputs.to(DEVICE)

            # é¢„æµ‹
            outputs = model(inputs)

            # æ”¶é›†ç»“æœ
            all_preds.extend(outputs.cpu().numpy().flatten())
            all_labels.extend(labels.numpy().flatten())

    # è½¬æ¢æ ¼å¼
    all_preds = np.array(all_preds)
    all_labels = np.array(all_labels)

    # 4. è®¡ç®—æŒ‡æ ‡
    rmse = np.sqrt(np.mean((all_preds - all_labels) ** 2))
    r2 = r2_score(all_labels, all_preds)

    print("\n" + "=" * 30)
    print(f"ğŸ“Š Evaluation Results:")
    print(f"   RMSE: {rmse:.4f} mm/s")
    print(f"   RÂ²  : {r2:.4f}")
    print("=" * 30)

    # 5. ç»˜å›¾
    plot_results(all_preds, all_labels)


if __name__ == "__main__":
    main()