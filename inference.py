import torch
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os
from model import SnnRegressor

# ================= é…ç½®åŒºåŸŸ =================
# æ¨¡å‹è·¯å¾„
MODEL_PATH = "/data/zm/12.22/02_snn_dropout_0.3203.pth"
# å¾…æµ‹è¯•çš„ CSV æ–‡ä»¶è·¯å¾„ (å¯ä»¥æ˜¯ä»»ä½•ä¸€ä¸ªæœªè§è¿‡çš„æ–°æ–‡ä»¶)
TEST_FILE = "/data/zm/12.24_data/0.5mm_clip.csv"

# è¿™é‡Œçš„ ROI å¿…é¡»å’Œè®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´ï¼
ROI = {'row_start': 400, 'row_end': 499, 'col_start': 0, 'col_end': 1280}
CROP_SIZE = 64
WINDOW_SIZE_MS = 25
STRIDE_MS = 25  # æ¨ç†æ­¥é•¿ï¼Œè¶Šå°æ›²çº¿è¶Šå¯†

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")


def preprocess_and_voxelize(df_chunk, t_start):
    """
    å°†ä¸€å°æ®µ DataFrame æ•°æ®å®æ—¶è½¬æ¢ä¸º SNN è¾“å…¥ Tensor
    """
    # æå–æ•°æ® (å‡è®¾ pandas è¯»è¿›æ¥åˆ—åæ˜¯ col, row, i, p, t)
    # æ ¹æ®ä½ æœ€æ–°çš„ check ç»“æœï¼Œä½ çš„ csv æ˜¯ 5 åˆ—
    x = df_chunk.iloc[:, 0].values
    y = df_chunk.iloc[:, 1].values
    # i = df_chunk.iloc[:, 2].values # intensity æš‚æ—¶ä¸ç”¨
    p = df_chunk.iloc[:, 3].values  # p
    t = df_chunk.iloc[:, 4].values  # t

    # å½’ä¸€åŒ– Y
    y_norm = y - ROI['row_start']

    # åªæœ‰åœ¨ ROI å†…çš„äº‹ä»¶æ‰æœ‰æ•ˆ
    mask = (y_norm >= 0) & (y_norm < (ROI['row_end'] - ROI['row_start']))

    if not mask.any(): return None

    x = x[mask]
    y_norm = y_norm[mask]
    p = p[mask]
    t = t[mask]

    # ä¸­å¿ƒè£å‰ª (Center Crop) - æ¨ç†æ—¶æˆ‘ä»¬é€šå¸¸çœ‹ä¸­å¿ƒ
    roi_h = ROI['row_end'] - ROI['row_start']
    roi_w = ROI['col_end'] - ROI['col_start']

    x_start = (roi_w - CROP_SIZE) // 2
    y_start = (roi_h - CROP_SIZE) // 2

    # äºŒæ¬¡ç­›é€‰ (Crop å†…)
    crop_mask = (x >= x_start) & (x < x_start + CROP_SIZE) & \
                (y_norm >= y_start) & (y_norm < y_start + CROP_SIZE)

    if not crop_mask.any(): return None

    x = x[crop_mask] - x_start
    y_norm = y_norm[crop_mask] - y_start
    p = p[crop_mask]
    t = t[crop_mask]

    # æ„å»º Voxel Grid
    T_bins = int(WINDOW_SIZE_MS / 1)  # 1ms per bin -> T=25
    grid = torch.zeros((T_bins, 2, CROP_SIZE, CROP_SIZE), dtype=torch.float32)

    # ææ€§é’³ä½
    ps = np.clip(p, 0, 1).astype(int)
    # æ—¶é—´ç´¢å¼•
    t_idx = ((t - t_start) / 1000).astype(int)
    t_idx = np.clip(t_idx, 0, T_bins - 1)
    # åæ ‡ç´¢å¼•
    xs = np.clip(x, 0, CROP_SIZE - 1).astype(int)
    ys = np.clip(y_norm, 0, CROP_SIZE - 1).astype(int)

    # å¡«å…… Tensor
    grid[t_idx, ps, ys, xs] = 1.0

    return grid


def predict_single_file(file_path):
    print(f"ğŸš€ Loading model from {MODEL_PATH}...")
    model = SnnRegressor(crop_size=CROP_SIZE).to(DEVICE)
    try:
        model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))
        model.eval()
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return

    print(f"ğŸ“‚ Reading file: {file_path}")

    try:
        # å…ˆè¯»ç¬¬ä¸€è¡Œè·å–èµ·å§‹æ—¶é—´ (å‡è®¾ç¬¬5åˆ—æ˜¯æ—¶é—´)
        df_head = pd.read_csv(file_path, header=None, nrows=1)
        t_global_start = df_head.iloc[0, 4]

        # è¯»æ•°æ® (ä¸ºäº†æ¼”ç¤ºï¼Œåªè¯»å‰ 300ä¸‡è¡Œï¼Œçº¦ 1-2ç§’)
        # names å‚æ•°ç¡®ä¿åˆ—å¯¹é½
        df = pd.read_csv(file_path, header=None, nrows=30000000,
                         names=['col', 'row', 'i', 'p', 't'])
    except Exception as e:
        print(f"Error reading CSV: {e}")
        return

    # æ»‘åŠ¨çª—å£é¢„æµ‹
    preds = []
    timestamps = []

    window_us = WINDOW_SIZE_MS * 1000
    stride_us = STRIDE_MS * 1000

    t_min = df['t'].min()
    t_max = df['t'].max()
    curr_t = t_min

    print("Running inference...")

    while curr_t + window_us < t_max:
        # è·å–çª—å£å†…æ•°æ®
        mask = (df['t'] >= curr_t) & (df['t'] < curr_t + window_us)
        df_chunk = df[mask]

        # åªæœ‰å½“çª—å£å†…æœ‰è¶³å¤Ÿäº‹ä»¶æ‰é¢„æµ‹ (æ¯”å¦‚ >100)
        if len(df_chunk) > 10:
            grid = preprocess_and_voxelize(df_chunk, curr_t)

            if grid is not None:
                # å¢åŠ  Batch ç»´åº¦ [1, T, 2, H, W]
                input_tensor = grid.unsqueeze(0).to(DEVICE)

                with torch.no_grad():
                    pred_v = model(input_tensor).item()
                    preds.append(pred_v)
                    timestamps.append((curr_t - t_global_start) / 1e6)  # ç§’

        curr_t += stride_us

    # ç»˜å›¾
    if len(preds) == 0:
        print("âŒ æœªç”Ÿæˆä»»ä½•é¢„æµ‹ç»“æœï¼Œå¯èƒ½æ˜¯æ•°æ®ä¸è¶³æˆ–ROIè®¾ç½®é”™è¯¯")
        return

    plt.figure(figsize=(10, 5))
    plt.plot(timestamps, preds, label='Predicted Velocity', alpha=0.7)

    # ç”»å¹³å‡çº¿
    mean_val = np.mean(preds)
    plt.axhline(mean_val, color='r', linestyle='--', label=f'Mean: {mean_val:.4f}')

    plt.xlabel('Time (s)')
    plt.ylabel('Velocity (mm/s)')
    plt.title(f'Inference: {os.path.basename(file_path)}')
    plt.legend()
    plt.grid(True, alpha=0.3)

    out_name = 'inference_result.png'
    plt.savefig(out_name)
    print(f"âœ… æ¨ç†å®Œæˆ! å¹³å‡é¢„æµ‹æµé€Ÿ: {mean_val:.4f} mm/s")
    print(f"   ç»“æœå·²ä¿å­˜ä¸º {out_name}")


if __name__ == "__main__":
    predict_single_file(TEST_FILE)